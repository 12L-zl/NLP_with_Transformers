{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a0e8a9",
   "metadata": {},
   "source": [
    "### 트랜스포머 애플리케이션 둘러보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff3a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab5b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
    "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
    "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
    "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
    "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
    "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
    "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f40ec",
   "metadata": {},
   "source": [
    "* 텍스트 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16441eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16ef9bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('text-classification') # 관심작업 이름 전달\n",
    "# text-classification : 주로 감성분석, 다중 분류, 다중 레이블 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d7908f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9015461802482605}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outputs = classifier(text)\n",
    "outputs # 각 예측은 하나의 dict형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f585f51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.901546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.901546"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d6fafb",
   "metadata": {},
   "source": [
    "* 개체명 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e80930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:982: UserWarning: Not enough free disk space to download the file. The expected file size is: 1334.40 MB. The target location C:\\Users\\knuyh\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english\\blobs only has 20.64 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f503f75af4df49598789515be30bac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  16%|#5        | 210M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:982: UserWarning: Not enough free disk space to download the file. The expected file size is: 1334.40 MB. The target location C:\\Users\\knuyh\\.cache\\huggingface\\hub\\models--dbmdz--bert-large-cased-finetuned-conll03-english\\blobs only has 10.15 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43648db8daa4ac0ac0c463b866f69f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  17%|#6        | 220M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3f35decf6b4e0da95ff56a646bc99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  17%|#6        | 220M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411a69f598d841d1a58a3393671cb39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  17%|#6        | 220M/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model dbmdz/bert-large-cased-finetuned-conll03-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForTokenClassification'>, <class 'transformers.models.bert.modeling_bert.BertForTokenClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification'>). See the original errors:\n\nwhile loading with AutoModelForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3428, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2835, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with BertForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3428, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFBertForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2835, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ner_tagger \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m, aggregation_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:895\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 895\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    896\u001b[0m         model,\n\u001b[0;32m    897\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    898\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    899\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    900\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    901\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    906\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:296\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    295\u001b[0m             error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 296\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     framework \u001b[38;5;241m=\u001b[39m infer_framework(model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not load model dbmdz/bert-large-cased-finetuned-conll03-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForTokenClassification'>, <class 'transformers.models.bert.modeling_bert.BertForTokenClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification'>). See the original errors:\n\nwhile loading with AutoModelForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3428, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFAutoModelForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2835, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with BertForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 3428, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\nwhile loading with TFBertForTokenClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 283, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 2835, in from_pretrained\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 402, in cached_file\n    resolved_file = hf_hub_download(\n                    ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1221, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1367, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1884, in _download_to_tmp_and_move\n    http_get(\n  File \"C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 542, in http_get\n    temp_file.write(chunk)\nOSError: [Errno 28] No space left on device\n\n\n"
     ]
    }
   ],
   "source": [
    "ner_tagger = pipeline('ner', aggregation_strategy = 'simple') # 모델 예측에 따라 단어 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)\n",
    "# ORG : 조직, LOC : 위치, PER : 사람, MISC : 그 외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989132fd",
   "metadata": {},
   "source": [
    "* 질문 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0645a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pipeline('question-answering')\n",
    "question = 'What does the customer want?'\n",
    "outputs = reader(question = question, context = text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db43bb4",
   "metadata": {},
   "source": [
    "* 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "outputs = summarizer(text, max_length = 60, clean_up_tokenization_spaces = True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fa7a9",
   "metadata": {},
   "source": [
    "* 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline('translation_en_to_de',\n",
    "                     model = 'Helsinki-NLP/opus-mt-en-de') # 영어 -> 독어\n",
    "outputs = translator(text, clean_up_tokenization_spaces = True, min_length = 100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f4b51",
   "metadata": {},
   "source": [
    "* 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbc834",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation')\n",
    "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    "# 자동완성기능\n",
    "prompt = text + \"\\n\\nCustomer service response:\\n\" + response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe89bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
