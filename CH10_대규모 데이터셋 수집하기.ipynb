{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1fa81e",
   "metadata": {},
   "source": [
    "### 대규모 데이터셋 수집하기\n",
    "#### 대규모 말뭉치 구축의 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf4bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee0052fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPT vs GPT-2 비교\n",
    "# GPT : BookCorpus에서 훈련\n",
    "# GPT-2 : 웹페이지, 블로그, 레딧에 링크된 뉴스 기사에서 훈련\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generation_gpt = pipeline('text-generation', model = 'openai-gpt')\n",
    "generation_gpt2 = pipeline('text-generation', model = 'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd5337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT  크기: 116.5M parameters\n",
      "GPT2 크기: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 개수 출력\n",
    "def model_size(model) :\n",
    "    return sum(t.numel() for t in model.parameters())\n",
    "\n",
    "print(f\"GPT  크기: {model_size(generation_gpt.model)/1000**2:.1f}M parameters\")\n",
    "print(f\"GPT2 크기: {model_size(generation_gpt2.model)/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5afa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 자동 완성:\n",
      "1.\n",
      "When they came back, he could not take his eyes off the fire pit. he could also not look at lily and luke. he could not look at them with fear or disgust. his breath became shallow and shallow, and he nearly hyperventilated when\n",
      "2.\n",
      "When they came back to her, she began to cry softly, her shoulders shaking. \n",
      " i put my arms around her and held her tight. \" it's okay, mom. it's all gon na be okay. \" \n",
      " i held her and\n",
      "3.\n",
      "When they came back. \n",
      " \" it's okay. i was just taking a shower, \" she said. \n",
      " \" but i need to wash your hair. \" \n",
      " \" that doesn't count. it's not really mine. \" \n",
      " he kissed\n",
      "\n",
      "GPT-2 자동 완성:\n",
      "1.\n",
      "When they came back to the farm it was clear they had just started to pick them up. It was an early morning call and they took me aside, said 'We're on the way. Let's get out there and do something interesting,'\"\n",
      "2.\n",
      "When they came back, they were in a hurry, hoping for the news report of the police report, but they had no idea how to proceed. The next day, however, they were called in to the station. They were told that a\n",
      "3.\n",
      "When they came back to the game, however, they also saw the players had moved in a direction where players would be less likely to run in this way or for other reasons. Some were talking about the possibility of having players be able to walk\n"
     ]
    }
   ],
   "source": [
    "def enum_pipeline_ouputs(pipe, prompt, num_return_sequences):\n",
    "    out = pipe(prompt, num_return_sequences=num_return_sequences,\n",
    "               clean_up_tokenization_spaces=True)\n",
    "    return \"\\n\".join(f\"{i+1}.\" + s[\"generated_text\"] for i, s in enumerate(out))\n",
    "\n",
    "prompt = \"\\nWhen they came back\"\n",
    "print(\"GPT 자동 완성:\\n\" + enum_pipeline_ouputs(generation_gpt, prompt, 3))\n",
    "print(\"\")\n",
    "print(\"GPT-2 자동 완성:\\n\" + enum_pipeline_ouputs(generation_gpt2, prompt, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6683d1b",
   "metadata": {},
   "source": [
    "GPT : 로맨스로 편향된 부분 있음, 남자와 여자의 낭만적인 대화로 보임  \n",
    "GPT-2 : 레딧 기사에 연결된 웹 텍스트에서 훈련되어 블로그 같은 내용이나 모험적인 요소를 담고 있고 중립적인 they 사용  \n",
    "\n",
    "* 구글 빅쿼리로 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6ec99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b085b35e1543c29aa2e231887b87f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DownloadConfig\n",
    "\n",
    "remote_dataset = load_dataset('transformersbook/codeparrot', split=\"train\",\n",
    "                              streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50767c81",
   "metadata": {},
   "source": [
    "### 토크나이저 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6466c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tok_list(tokenizer, string):\n",
    "    input_ids = tokenizer(string, add_special_tokens=False)[\"input_ids\"]\n",
    "    return [tokenizer.decode(tok) for tok in input_ids]\n",
    "\n",
    "tokenizer_T5 = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "tokenizer_camembert = AutoTokenizer.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5755d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sex\"에 대한 T5 토큰: ['', 's', 'ex']\n",
      "\"being\"에 대한 CamemBERT 토큰: ['be', 'ing']\n"
     ]
    }
   ],
   "source": [
    "print(f'\"sex\"에 대한 T5 토큰: {tok_list(tokenizer_T5,\"sex\")}')\n",
    "print(f'\"being\"에 대한 CamemBERT 토큰: {tok_list(tokenizer_camembert,\"being\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee98a6",
   "metadata": {},
   "source": [
    "짧고, 평범한 단어를 부분으로 나누면 모델에 입력되는 시퀀스 길이가 늘어나 비효율적  \n",
    "\n",
    "* 토크나이저 성능 측정하기\n",
    "    * 부분단어 생산력 : 토큰화된 단어마다 생성되는 부분단어의 평균 개수 계산\n",
    "    * 연속 단어의 비율 : 말뭉치에서 적어도 두 개의 부분 토큰으로 분할된 토큰화된 단어의 비율\n",
    "    * 커버리지 측정값 : 토큰화된 말뭉치에서 알 수 없는 단어나 거의 사용되지 않는 토큰의 비율\n",
    "    \n",
    "* 파이썬 코드를 위한 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "574acb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġsay', '_', 'hello', '():', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġprint', '(\"', 'Hello', ',', 'ĠWorld', '!\"', ')', 'Ċ', '#', 'ĠPrint', 'Ġit', 'Ċ', 'say', '_', 'hello', '()', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "python_code = r\"\"\"def say_hello():\n",
    "    print(\"Hello, World!\")\n",
    "# Print it\n",
    "say_hello()\n",
    "\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "print(tokenizer(python_code).tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5087638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.backend_tokenizer.normalizer)\n",
    "# GPT-2는 정규화 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c1c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('def', (0, 3)), ('Ġsay', (3, 7)), ('_', (7, 8)), ('hello', (8, 13)), ('():', (13, 16)), ('ĊĠĠĠ', (16, 20)), ('Ġprint', (20, 26)), ('(\"', (26, 28)), ('Hello', (28, 33)), (',', (33, 34)), ('ĠWorld', (34, 40)), ('!\")', (40, 43)), ('Ċ', (43, 44)), ('#', (44, 45)), ('ĠPrint', (45, 51)), ('Ġit', (51, 54)), ('Ċ', (54, 55)), ('say', (55, 58)), ('_', (58, 59)), ('hello', (59, 64)), ('()', (64, 66)), ('Ċ', (66, 67))]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(python_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72246d",
   "metadata": {},
   "source": [
    "토크나이저는 문자열과 토큰 사이를 전환하는 데 매우 유용한 오프셋트래킹 기능이 있다. 입력 문자열에 대한 모든 연산이 추적되기에 토큰화 이후 토큰이 입력 문자열의 어떤 부분에 해당하는지 정확하게 알 수 있다.  \n",
    "\n",
    "숫자는 단순히 토큰이 유래된 원본 문자열의 위치로, 일부 문자가 정규화 단계에서 삭제되더라도 각 토큰을 원본 문자열의 해당 부분에 연결 가능  \n",
    "기이한 문자는 유니코드 문자를 바이트의 시퀀스로 변환하여 생긴 것  \n",
    "(`Ċ` : 줄바꿈 , `Ġ` : 공백)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063a9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`a`는 단일 바이트 `b'a'`로 인코딩됩니다: 97\n",
      "`€`는 세 바이트 `b'\\xe2\\x82\\xac'`로 인코딩됩니다: [226, 130, 172]\n"
     ]
    }
   ],
   "source": [
    "a, e = u\"a\", u\"€\"\n",
    "byte = ord(a.encode(\"utf-8\"))\n",
    "print(f'`{a}`는 단일 바이트 `{a.encode(\"utf-8\")}`로 인코딩됩니다: {byte}')\n",
    "byte = [ord(chr(i)) for i in e.encode(\"utf-8\")]\n",
    "print(f'`{e}`는 세 바이트 `{e.encode(\"utf-8\")}`로 인코딩됩니다: {byte}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624d4870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 어휘 사전 크기: 256\n",
      "첫 번째 원소: `!`, last element: `Ń`\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode\n",
    "\n",
    "byte_to_unicode_map = bytes_to_unicode()\n",
    "unicode_to_byte_map = dict((v, k) for k, v in byte_to_unicode_map.items())\n",
    "base_vocab = list(unicode_to_byte_map.keys())\n",
    "\n",
    "print(f'기본 어휘 사전 크기: {len(base_vocab)}')\n",
    "print(f'첫 번째 원소: `{base_vocab[0]}`, last element: `{base_vocab[-1]}`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc1f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Character</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Mapped bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regular characters</td>\n",
       "      <td>`a` and `?`</td>\n",
       "      <td>97 and 63</td>\n",
       "      <td>`a` and `?`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nonprintable control character (carriage return)</td>\n",
       "      <td>`U+000D`</td>\n",
       "      <td>13</td>\n",
       "      <td>`č`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A space</td>\n",
       "      <td>` `</td>\n",
       "      <td>32</td>\n",
       "      <td>`Ġ`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A nonbreakable space</td>\n",
       "      <td>`\\xa0`</td>\n",
       "      <td>160</td>\n",
       "      <td>`ł`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A newline character</td>\n",
       "      <td>`\\n`</td>\n",
       "      <td>10</td>\n",
       "      <td>`Ċ`</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Description    Character      Bytes  \\\n",
       "0                                Regular characters  `a` and `?`  97 and 63   \n",
       "1  Nonprintable control character (carriage return)     `U+000D`         13   \n",
       "2                                           A space          ` `         32   \n",
       "3                              A nonbreakable space       `\\xa0`        160   \n",
       "4                               A newline character         `\\n`         10   \n",
       "\n",
       "  Mapped bytes  \n",
       "0  `a` and `?`  \n",
       "1          `č`  \n",
       "2          `Ġ`  \n",
       "3          `ł`  \n",
       "4          `Ċ`  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BPE 문자 매핑의 예\n",
    "import pandas as pd\n",
    "from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode\n",
    "\n",
    "byte_to_unicode_map = bytes_to_unicode()\n",
    "unicode_to_byte_map = dict((v, k) for k, v in byte_to_unicode_map.items())\n",
    "base_vocab = list(unicode_to_byte_map.keys())\n",
    "\n",
    "examples = [\n",
    "    ['Regular characters', '`a` and `?`', f'{ord(\"a\")} and {ord(\"?\")}' , f'`{byte_to_unicode_map[ord(\"a\")]}` and `{byte_to_unicode_map[ord(\"?\")]}`'],\n",
    "    ['Nonprintable control character (carriage return)', '`U+000D`', f'13', f'`{byte_to_unicode_map[13]}`'],\n",
    "    ['A space', '` `', f'{ord(\" \")}', f'`{byte_to_unicode_map[ord(\" \")]}`'],\n",
    "    ['A nonbreakable space', '`\\\\xa0`', '160', f'`{byte_to_unicode_map[ord(chr(160))]}`'],\n",
    "    ['A newline character', '`\\\\n`', '10', f'`{byte_to_unicode_map[ord(chr(10))]}`'],\n",
    "]\n",
    "\n",
    "pd.DataFrame(examples, columns = ['Description', 'Character', 'Bytes', 'Mapped bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb1fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('def', (0, 3)), ('Ġsay', (3, 7)), ('_', (7, 8)), ('hello', (8, 13)), ('():', (13, 16)), ('ĊĠĠĠ', (16, 20)), ('Ġprint', (20, 26)), ('(\"', (26, 28)), ('Hello', (28, 33)), (',', (33, 34)), ('ĠWorld', (34, 40)), ('!\")', (40, 43)), ('Ċ', (43, 44)), ('#', (44, 45)), ('ĠPrint', (45, 51)), ('Ġit', (51, 54)), ('Ċ', (54, 55)), ('say', (55, 58)), ('_', (58, 59)), ('hello', (59, 64)), ('()', (64, 66)), ('Ċ', (66, 67))]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(python_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b79761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘 사전의 크기: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"어휘 사전의 크기: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a9f3e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġsay', '_', 'hello', '():', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġprint', '(\"', 'Hello', ',', 'ĠWorld', '!\"', ')', 'Ċ', '#', 'ĠPrint', 'Ġit', 'Ċ', 'say', '_', 'hello', '()', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(python_code).tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f41ba",
   "metadata": {},
   "source": [
    "* 토크나이저 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2447e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ', ' =================================================================', ' ----------------------------------------------------------------', '----------------------------------------------------------------', '................................................................', '================================================================', '________________________________________________________________', 'ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ']\n"
     ]
    }
   ],
   "source": [
    "# GPT-2 어휘사전에서 가장 긴 단어\n",
    "tokens = sorted(tokenizer.vocab.items(), key=lambda x: len(x[0]), reverse=True)\n",
    "print([f'{tokenizer.convert_tokens_to_string([t])}' for t, _ in tokens[:8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a5a96d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', ' gazed', ' informants', ' Collider', ' regress', 'ominated', ' amplification', 'Compar', '….\"', ' (/', 'Commission', ' Hitman']\n"
     ]
    }
   ],
   "source": [
    "# 어휘사전의 마지막에 등록된 단어\n",
    "tokens = sorted(tokenizer.vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "print([f'{tokenizer.convert_tokens_to_string([t])}' for t, _ in tokens[:12]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b834374",
   "metadata": {},
   "source": [
    "<|endoftext|> : 텍스트 시퀀스의 끝 지정할 때 사용하는 특수 토큰으로, BPE 어휘사전이 구축된 후 추가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35fa1660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a769c6c2bcd41709ba1762eab8e81a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6801895d48d84466a34198e03da8ff1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "length = 100000\n",
    "dataset_name = 'transformersbook/codeparrot-train'\n",
    "dataset = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "iter_dataset = iter(dataset)\n",
    "\n",
    "def batch_iterator(batch_size=10):\n",
    "    for _ in tqdm(range(0, length, batch_size)):\n",
    "        yield [next(iter_dataset)['content'] for _ in range(batch_size)]\n",
    "\n",
    "new_tokenizer = tokenizer.train_new_from_iterator(batch_iterator(),\n",
    "                                                  vocab_size=12500,\n",
    "                                                  initial_alphabet=base_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c34065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  ', '    ', '   ', '        ', 'se', 'in', '       ', 're', 'on', 'te', '\\n       ', '\\n        ', 'or', 'st', 'de', '\\n   ', 'th', 'le', ' =', 'lf', 'self', 'me', 'al']\n"
     ]
    }
   ],
   "source": [
    "# BPE 알고리즘이 만든 첫 단어\n",
    "# 256바이트는 건너뛰고 그다음에 추가된 첫 토큰\n",
    "tokens = sorted(new_tokenizer.vocab.items(), key=lambda x: x[1], reverse=False)\n",
    "print([f'{tokenizer.convert_tokens_to_string([t])}' for t, _ in tokens[257:280]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ececed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' capt', ' embedded', ' regarding', 'Bundle', '355', ' recv', ' dmp', ' vault', ' Mongo', ' possibly', 'implementation', 'Matches']\n"
     ]
    }
   ],
   "source": [
    "# 마지막 단어\n",
    "print([f'{new_tokenizer.convert_tokens_to_string([t])}' for t,_ in tokens[-12:]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7077e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġs', 'ay', '_', 'hello', '():', 'ĊĠĠĠ', 'Ġprint', '(\"', 'Hello', ',', 'ĠWor', 'ld', '!\")', 'Ċ', '#', 'ĠPrint', 'Ġit', 'Ċ', 's', 'ay', '_', 'hello', '()', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "print(new_tokenizer(python_code).tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9df538b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 전체 예약어 개수: 35\n",
      "예약어 `await`는 어휘 사전에 없습니다.\n",
      "예약어 `finally`는 어휘 사전에 없습니다.\n",
      "예약어 `nonlocal`는 어휘 사전에 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import keyword\n",
    "\n",
    "print(f'파이썬 전체 예약어 개수: {len(keyword.kwlist)}')\n",
    "for keyw in keyword.kwlist:\n",
    "    if keyw not in new_tokenizer.vocab:\n",
    "        print(f'예약어 `{keyw}`는 어휘 사전에 없습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974471c",
   "metadata": {},
   "source": [
    "finally 같이 매우 자주 등장하는 예약어가 어휘사전에 없다. 데이터셋에서 더 많은 샘플을 가져와 더 큰 어휘사전을 만들어야."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10fc0f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cd1423bbcd45cf81b64e0ee6f0a067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = 200000\n",
    "new_tokenizer_larger = tokenizer.train_new_from_iterator(batch_iterator(),\n",
    "    vocab_size=32768, initial_alphabet=base_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "943f270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" '<?\", 'Functional', ' Images', 'encoders', ' bibrec', ' OPTIONAL', ' rdclass', 'SocketAddressTag', '资金', 'DEPLOYMENT', '经纪公司代码', \")'],\"]\n"
     ]
    }
   ],
   "source": [
    "# 마지막 토큰\n",
    "tokens = sorted(new_tokenizer_larger.vocab.items(), key=lambda x: x[1],\n",
    "                reverse=False)\n",
    "print([f'{tokenizer.convert_tokens_to_string([t])}' for t, _ in tokens[-12:]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d603b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġsay', '_', 'hello', '():', 'ĊĠĠĠ', 'Ġprint', '(\"', 'Hello', ',', 'ĠWorld', '!\")', 'Ċ', '#', 'ĠPrint', 'Ġit', 'Ċ', 'say', '_', 'hello', '()', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "print(new_tokenizer_larger(python_code).tokens())\n",
    "# 들여쓰기가 어휘사전에 유지됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6311f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예약어 `nonlocal`는 어휘 사전에 없습니다.\n"
     ]
    }
   ],
   "source": [
    "for keyw in keyword.kwlist:\n",
    "    if keyw not in new_tokenizer_larger.vocab:\n",
    "        print(f'예약어 `{keyw}`는 어휘 사전에 없습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234c665",
   "metadata": {},
   "source": [
    "드문 단어라 어휘사전에 없는 것이 합당함\n",
    "\n",
    "### 밑바닥부터 모델 훈련하기\n",
    "#### 사전 훈련 목표\n",
    "* 코잘 언어 모델링\n",
    "    * 코드 샘플 시작 부분을 모델에게 제공하고 코드의 나머지 부분을 생성해 완성하라고 요청하는 것\n",
    "    * 레이블이 없는 데이터셋을 사용하는 자기 지도 훈련 목표\n",
    "* 마스크드 언어 모델링\n",
    "    * 모델에게 잡음이 섞인 코드 샘플을 주고 깨끗한 원본 샘플을 재구성하라고 요청하는 자기 지도 훈련 목표\n",
    "* 시퀀스-투-시퀀스 훈련\n",
    "    * 정규식 같은 수동 규칙으로 주석이나 독스트링을 코드에서 분리해 레이블링된 데이터셋으로 사용하도록 (코드, 주석) 쌍의 대규모 데이터셋을 구축하는 작업\n",
    "    \n",
    "#### 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fec54f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('transformersbook/codeparrot')\n",
    "config = AutoConfig.from_pretrained(\"gpt2\", vocab_size=len(tokenizer))\n",
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4928843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 (xl) 크기: 111.0M parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'GPT-2 (xl) 크기: {model_size(model)/1000**2:.1f}M parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbf968",
   "metadata": {},
   "source": [
    "#### 데이터로더 구축하기\n",
    "시퀀스 마지막 부분을 많이 잃지 않도록, 여러 샘플을 토큰화한 다음 특수한 EOS 토큰으로 연결해 매우 긴 시퀀스를 만든다. 이 시퀀스를 동일한 크기의 청크로 나누면 마지막 데이터에서 손실되는 부분이 미미하다.\n",
    "\n",
    "<br>\n",
    "\n",
    "input_characters = number_of_sequences * sequence_length * characters_per_token  \n",
    "* input_characters : 토크나이저에 입력된 문자열에 있는 문자의 개수\n",
    "* number_of_sequences : 토크나이저로부터 얻으려는 시퀀스의 개수\n",
    "* sequence_length : 토크나이저가 반환한 각 시퀀스의 토큰 개수\n",
    "* characters_per_token : 사전에 추정해야 하는 각 출력 토큰의 평균 문자 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc11838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7430c60e011a43068567cbc82fdb8873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe123238bbe445d99cafc7184f603c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2605 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# 토큰의 평균 문자 길이\n",
    "examples, total_characters, total_tokens = 500, 0, 0\n",
    "dataset = load_dataset('transformersbook/codeparrot-train', split='train',\n",
    "                       streaming=True)\n",
    "\n",
    "for _, example in tqdm(zip(range(examples), iter(dataset)), total=examples):\n",
    "    total_characters += len(example['content'])\n",
    "    total_tokens += len(tokenizer(example['content']).tokens())\n",
    "\n",
    "characters_per_token = total_characters / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3de7ceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6233025034779565\n"
     ]
    }
   ],
   "source": [
    "print(characters_per_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03fd3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataset, seq_length=1024,\n",
    "                 num_of_sequences=1024, chars_per_token=3.6):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.input_characters = seq_length * chars_per_token * num_of_sequences\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.input_characters:\n",
    "                    m=f\"Buffer full: {buffer_len}>={self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    break\n",
    "                try:\n",
    "                    m=f\"Fill buffer: {buffer_len}<{self.input_characters:.0f}\"\n",
    "                    print(m)\n",
    "                    buffer.append(next(iterator)[\"content\"])\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    iterator = iter(self.dataset)\n",
    "\n",
    "            all_token_ids = []\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)\n",
    "            for tokenized_input in tokenized_inputs['input_ids']:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            \n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    yield torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d99329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill buffer: 0<36864\n",
      "Fill buffer: 1381<36864\n",
      "Fill buffer: 5239<36864\n",
      "Fill buffer: 19527<36864\n",
      "Fill buffer: 24263<36864\n",
      "Fill buffer: 25338<36864\n",
      "Buffer full: 40809>=36864\n",
      "시퀀스 길이: [1024, 1024, 1024, 1024, 1024]\n"
     ]
    }
   ],
   "source": [
    "shuffled_dataset = dataset.shuffle(buffer_size=100)\n",
    "constant_length_dataset = ConstantLengthDataset(tokenizer, shuffled_dataset,\n",
    "                                                num_of_sequences=10)\n",
    "dataset_iterator = iter(constant_length_dataset)\n",
    "\n",
    "lengths = [len(b) for _, b in zip(range(5), dataset_iterator)]\n",
    "print(f\"시퀀스 길이: {lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8109ac",
   "metadata": {},
   "source": [
    "#### 훈련 루프 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebedf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "# 작은 모델에 해당하는 파라미터\n",
    "config = {\"train_batch_size\": 2, # 12\n",
    "          \"valid_batch_size\": 2, # 12\n",
    "          \"weight_decay\": 0.1,\n",
    "          \"shuffle_buffer\": 1000,\n",
    "          \"learning_rate\": 2e-4, # 5e-4\n",
    "          \"lr_scheduler_type\": \"cosine\",\n",
    "          \"num_warmup_steps\": 750, # 2000\n",
    "          \"gradient_accumulation_steps\": 16, # 1\n",
    "          \"max_train_steps\": 50000, # 150000\n",
    "          \"max_eval_steps\": -1,\n",
    "          \"seq_length\": 1024,\n",
    "          \"seed\": 1,\n",
    "          \"save_checkpoint_steps\": 50000} # 15000\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bca24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import wandb\n",
    "\n",
    "def setup_logging(project_name):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\", level=logging.INFO, handlers=[\n",
    "        logging.FileHandler(f\"log/debug_{accelerator.process_index}.log\"),\n",
    "        logging.StreamHandler()])\n",
    "    if accelerator.is_main_process: # 로깅 한 번만 설정\n",
    "        wandb.init(project=project_name, config=args)\n",
    "        run_name = wandb.run.name\n",
    "        tb_writer = SummaryWriter()\n",
    "        tb_writer.add_hparams(vars(args), {'0': 0})\n",
    "        logger.setLevel(logging.INFO)\n",
    "        datasets.utils.logging.set_verbosity_debug()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        tb_writer = None\n",
    "        run_name = ''\n",
    "        logger.setLevel(logging.ERROR)\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "    return logger, tb_writer, run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59eb73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(step, metrics):\n",
    "    logger.info(f\"Step {step}: {metrics}\")\n",
    "    if accelerator.is_main_process:\n",
    "        wandb.log(metrics)\n",
    "        [tb_writer.add_scalar(k, v, step) for k, v in metrics.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15bc10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "def create_dataloaders(dataset_name):\n",
    "    train_data = load_dataset(dataset_name+'-train', split=\"train\",\n",
    "                              streaming=True)\n",
    "    train_data = train_data.shuffle(buffer_size=args.shuffle_buffer,\n",
    "                                    seed=args.seed)\n",
    "    valid_data = load_dataset(dataset_name+'-valid', split=\"validation\",\n",
    "                              streaming=True)\n",
    "    \n",
    "    train_dataset = ConstantLengthDataset(tokenizer, train_data,\n",
    "                                          seq_length=args.seq_length)\n",
    "    valid_dataset = ConstantLengthDataset(tokenizer, valid_data,\n",
    "                                          seq_length=args.seq_length)\n",
    "    \n",
    "    train_dataloader=DataLoader(train_dataset, batch_size=args.train_batch_size)\n",
    "    eval_dataloader=DataLoader(valid_dataset, batch_size=args.valid_batch_size)\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49feded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화\n",
    "# LayerNorm 가중치에는 가중치 감쇠 적용 X\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [{'params': params_with_wd, 'weight_decay': args.weight_decay},\n",
    "            {'params': params_without_wd, 'weight_decay': 0.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "734121fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch, labels=batch)\n",
    "        loss = outputs.loss.repeat(args.valid_batch_size)\n",
    "        losses.append(accelerator.gather(loss))\n",
    "        if args.max_eval_steps > 0 and step >= args.max_eval_steps: break\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = torch.tensor(float(\"inf\"))\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08ad1b",
   "metadata": {},
   "source": [
    "### 결과 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0340a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "model_ckpt = 'transformersbook/codeparrot-small'\n",
    "generation = pipeline('text-generation', model=model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "165a33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import set_seed \n",
    "\n",
    "def first_block(string):\n",
    "    return re.split('\\nclass|\\ndef|\\n#|\\n@|\\nprint|\\nif', string)[0].rstrip()\n",
    "\n",
    "def complete_code(pipe, prompt, max_length=64, num_completions=4, seed=1):\n",
    "    set_seed(seed)\n",
    "    gen_kwargs = {\"temperature\":0.4, \"top_p\":0.95, \"top_k\":0, \"num_beams\":1,\n",
    "                  \"do_sample\":True,}\n",
    "    code_gens = generation(prompt, num_return_sequences=num_completions, \n",
    "                            max_length=max_length, **gen_kwargs)\n",
    "    code_strings = []\n",
    "    for code_gen in code_gens:\n",
    "        generated_code = first_block(code_gen['generated_text'][len(prompt):])\n",
    "        code_strings.append(generated_code)\n",
    "    print(('\\n'+'='*80 + '\\n').join(code_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fea3137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return (a / b) * (a + b) / 2.0\n",
      "================================================================================\n",
      "\n",
      "    return a * b\n",
      "================================================================================\n",
      "\n",
      "    return a / b\n",
      "================================================================================\n",
      "\n",
      "    return a / b\n"
     ]
    }
   ],
   "source": [
    "# 사각형 면적 계산\n",
    "prompt = '''def area_of_rectangle(a: float, b: float):\n",
    "    \"\"\"Return the area of the rectangle.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd4ecbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return [url for url in re.findall(r'<a href=\"(http://[^\"]+\\.html)\"', html)]\n",
      "================================================================================\n",
      "\n",
      "    return [url for url in re.findall(r'<a href=\"(.*?)\"', html) if url]\n",
      "================================================================================\n",
      "\n",
      "    return [url for url in re.findall(r'<a href=\"(.*?)\"', html) if url]\n",
      "================================================================================\n",
      "\n",
      "    return [url for url in re.findall(r'<a href=\"(.*?)\" class=\"url\">', html)]\n"
     ]
    }
   ],
   "source": [
    "# HTML에서 URL 추출\n",
    "prompt = '''def get_urls_from_html(html):\n",
    "    \"\"\"Get all embedded URLs in a HTML string.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfb4405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/chat | /models | /spaces/black-forest-labs/FLUX.1-schnell | /spaces/black-forest-labs/FLUX.1-dev | /spaces/stabilityai/stable-fast-3d | /spaces/SkalskiP/florence-sam | /spaces/KwaiVGI/LivePortrait | /spaces | /datasets | /enterprise | /enterprise | /enterprise | /enterprise | /enterprise | /enterprise | /docs/transformers | /docs/diffusers | /docs/safetensors | /docs/huggingface_hub | /docs/tokenizers | /docs/peft | /docs/transformers.js | /docs/timm | /docs/trl | /docs/datasets | /docs/text-generation-inference | /docs/accelerate\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_urls_from_html(html):\n",
    "    return [url for url in re.findall(r'<a href=\"(.*?)\"', html) if url]\n",
    "\n",
    "print(\" | \".join(get_urls_from_html(requests.get('https://hf.co/').text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 함수를 넘파이를 사용하는 함수로 바꾸기\n",
    "model_ckpt = 'transformersbook/codeparrot'\n",
    "generation = pipeline('text-generation', model=model_ckpt)\n",
    "\n",
    "prompt = '''# a function in native python:\n",
    "def mean(a):\n",
    "    return sum(a)/len(a)\n",
    "\n",
    "# the same function using numpy:\n",
    "import numpy as np\n",
    "def mean(a):'''\n",
    "complete_code(generation, prompt, max_length=64)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "30510d0f",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e48586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 모델 생성\n",
    "prompt = '''X = np.random.randn(100, 100)\n",
    "y = np.random.randint(0, 1, 100)\n",
    "\n",
    "# fit random forest classifier with 20 estimators'''\n",
    "complete_code(generation, prompt, max_length=96)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "705e8ec3",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fda248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
